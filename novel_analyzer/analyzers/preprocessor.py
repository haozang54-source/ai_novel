"""
æ–‡ä»¶é¢„å¤„ç†æ¨¡å—
"""
import os
from typing import List, Dict
from utils.file_utils import FileUtils


class NovelPreprocessor:
    """å°è¯´é¢„å¤„ç†å™¨"""
    
    def __init__(self, novel_folder: str, config: dict):
        """
        åˆå§‹åŒ–é¢„å¤„ç†å™¨
        
        Args:
            novel_folder: å°è¯´æ–‡ä»¶å¤¹è·¯å¾„
            config: é…ç½®å­—å…¸
        """
        self.novel_folder = novel_folder
        self.config = config
        self.chapters = []
        self.statistics = {}
    
    def load_and_process(self) -> List[Dict]:
        """
        åŠ è½½å¹¶å¤„ç†æ‰€æœ‰ç« èŠ‚
        
        Returns:
            ç« èŠ‚åˆ—è¡¨
        """
        print(f"ğŸ“ æ­£åœ¨åŠ è½½å°è¯´æ–‡ä»¶: {self.novel_folder}")
        
        # åŠ è½½æ‰€æœ‰ç« èŠ‚
        encoding = self.config.get('preprocessing', {}).get('encoding', 'utf-8')
        self.chapters = FileUtils.load_novel_files(self.novel_folder, encoding)
        
        print(f"âœ“ æˆåŠŸåŠ è½½ {len(self.chapters)} ä¸ªç« èŠ‚")
        
        # æ¸…æ´—æ–‡æœ¬
        self._clean_chapters()
        
        # è¿‡æ»¤ç« èŠ‚
        self._filter_chapters()
        
        # ç”Ÿæˆç»Ÿè®¡ä¿¡æ¯
        self._generate_statistics()
        
        return self.chapters
    
    def _clean_chapters(self):
        """æ¸…æ´—æ‰€æœ‰ç« èŠ‚æ–‡æœ¬"""
        print("ğŸ§¹ æ­£åœ¨æ¸…æ´—æ–‡æœ¬...")
        for chapter in self.chapters:
            chapter['content'] = FileUtils.clean_text(chapter['content'])
            chapter['word_count'] = len(chapter['content'])
    
    def _filter_chapters(self):
        """è¿‡æ»¤ä¸ç¬¦åˆè¦æ±‚çš„ç« èŠ‚"""
        min_length = self.config.get('preprocessing', {}).get('min_chapter_length', 500)
        max_length = self.config.get('preprocessing', {}).get('max_chapter_length', 20000)
        
        filtered = []
        for chapter in self.chapters:
            if min_length <= chapter['word_count'] <= max_length:
                filtered.append(chapter)
            else:
                print(f"  è·³è¿‡ç« èŠ‚ {chapter['number']} (å­—æ•°: {chapter['word_count']})")
        
        if len(filtered) < len(self.chapters):
            print(f"âš ï¸  è¿‡æ»¤æ‰ {len(self.chapters) - len(filtered)} ä¸ªç« èŠ‚")
        
        self.chapters = filtered
    
    def _generate_statistics(self):
        """ç”Ÿæˆç»Ÿè®¡ä¿¡æ¯"""
        total_words = sum(ch['word_count'] for ch in self.chapters)
        avg_words = total_words // len(self.chapters) if self.chapters else 0
        
        self.statistics = {
            'total_chapters': len(self.chapters),
            'total_words': total_words,
            'average_chapter_length': avg_words,
            'min_chapter_length': min(ch['word_count'] for ch in self.chapters) if self.chapters else 0,
            'max_chapter_length': max(ch['word_count'] for ch in self.chapters) if self.chapters else 0
        }
        
        print("\nğŸ“Š ç»Ÿè®¡ä¿¡æ¯:")
        print(f"  æ€»ç« èŠ‚æ•°: {self.statistics['total_chapters']}")
        print(f"  æ€»å­—æ•°: {self.statistics['total_words']:,}")
        print(f"  å¹³å‡ç« èŠ‚é•¿åº¦: {self.statistics['average_chapter_length']:,} å­—")
        print(f"  ç« èŠ‚é•¿åº¦èŒƒå›´: {self.statistics['min_chapter_length']:,} - {self.statistics['max_chapter_length']:,} å­—\n")
    
    def get_statistics(self) -> Dict:
        """
        è·å–ç»Ÿè®¡ä¿¡æ¯
        
        Returns:
            ç»Ÿè®¡ä¿¡æ¯å­—å…¸
        """
        return self.statistics
