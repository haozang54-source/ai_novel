"""åŸºç¡€æ™ºèƒ½ä½“ç±»"""
import os
from abc import ABC, abstractmethod
from typing import Dict, Any, Optional
from dotenv import load_dotenv
from langchain_openai import ChatOpenAI
from langchain_ollama import ChatOllama

# åŠ è½½ç¯å¢ƒå˜é‡
load_dotenv()


class BaseAgent(ABC):
    """æ‰€æœ‰æ™ºèƒ½ä½“çš„åŸºç±»"""
    
    def __init__(self, llm=None, agent_name: str = "BaseAgent"):
        """
        åˆå§‹åŒ–æ™ºèƒ½ä½“
        
        Args:
            llm: è¯­è¨€æ¨¡å‹å®ä¾‹,å¦‚æœä¸ºNoneåˆ™ä½¿ç”¨é»˜è®¤é…ç½®
            agent_name: æ™ºèƒ½ä½“åç§°
        """
        self.agent_name = agent_name
        self.llm = llm or self._create_default_llm()
        self.memory = {}
        
    def _create_default_llm(self):
        """åˆ›å»ºé»˜è®¤çš„LLMå®ä¾‹,ä».envè¯»å–é…ç½®"""
        # ä»ç¯å¢ƒå˜é‡è¯»å–é…ç½®
        llm_provider = os.getenv("LLM_PROVIDER", "ollama").lower()
        ollama_model = os.getenv("OLLAMA_MODEL", "qwen2.5:7b")
        openai_model = os.getenv("OPENAI_MODEL", "gpt-4o-mini")
        temperature = float(os.getenv("LLM_TEMPERATURE", "0.7"))
        
        if llm_provider == "ollama":
            try:
                self.log(f"ğŸ¤– ä½¿ç”¨ Ollama æ¨¡å‹: {ollama_model}")
                return ChatOllama(
                    model=ollama_model,
                    temperature=temperature
                )
            except Exception as e:
                print(f"âš ï¸ Ollamaåˆå§‹åŒ–å¤±è´¥: {e}")
                print(f"ğŸ’¡ è¯·ç¡®ä¿ Ollama å·²å¯åŠ¨: ollama serve")
                print(f"ğŸ’¡ å¹¶å®‰è£…æ¨¡å‹: ollama pull {ollama_model}")
                raise
        elif llm_provider == "openai":
            try:
                self.log(f"ğŸ¤– ä½¿ç”¨ OpenAI æ¨¡å‹: {openai_model}")
                return ChatOpenAI(
                    model=openai_model,
                    temperature=temperature
                )
            except Exception as e:
                print(f"âš ï¸ OpenAIåˆå§‹åŒ–å¤±è´¥: {e}")
                print(f"ğŸ’¡ è¯·æ£€æŸ¥ OPENAI_API_KEY æ˜¯å¦é…ç½®æ­£ç¡®")
                raise
        else:
            raise Exception(f"âŒ ä¸æ”¯æŒçš„ LLM_PROVIDER: {llm_provider}ï¼Œè¯·ä½¿ç”¨ 'ollama' æˆ– 'openai'")
    
    @abstractmethod
    def run(self, input_data: Dict[str, Any]) -> Dict[str, Any]:
        """
        æ‰§è¡Œæ™ºèƒ½ä½“çš„ä¸»è¦ä»»åŠ¡
        
        Args:
            input_data: è¾“å…¥æ•°æ®
            
        Returns:
            æ‰§è¡Œç»“æœ
        """
        pass
    
    def invoke_llm(self, prompt: str) -> str:
        """
        è°ƒç”¨LLMç”Ÿæˆå†…å®¹
        
        Args:
            prompt: æç¤ºè¯
            
        Returns:
            ç”Ÿæˆçš„å†…å®¹
        """
        try:
            response = self.llm.invoke(prompt)
            return response.content if hasattr(response, 'content') else str(response)
        except Exception as e:
            return f"âŒ LLMè°ƒç”¨å¤±è´¥: {e}"
    
    def log(self, message: str):
        """è®°å½•æ—¥å¿—"""
        print(f"[{self.agent_name}] {message}")
